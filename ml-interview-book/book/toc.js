// Populate the sidebar
//
// This is a script, and not included directly in the page, to control the total size of the book.
// The TOC contains an entry for each page, so if each page includes a copy of the TOC,
// the total size of the page becomes O(n**2).
class MDBookSidebarScrollbox extends HTMLElement {
    constructor() {
        super();
    }
    connectedCallback() {
        this.innerHTML = '<ol class="chapter"><li class="chapter-item expanded affix "><a href="introduction.html">Introduction</a></li><li class="chapter-item expanded affix "><li class="part-title">Fundamentals</li><li class="chapter-item expanded "><a href="chapter_001.html"><strong aria-hidden="true">1.</strong> Why We Use Smaller Learning Rates: The Key to Stable ML Training</a></li><li class="chapter-item expanded "><a href="chapter_002.html"><strong aria-hidden="true">2.</strong> Train-Test Split Ratios: Beyond the 80:20 Rule</a></li><li class="chapter-item expanded "><a href="chapter_003.html"><strong aria-hidden="true">3.</strong> Understanding Covariance vs Correlation: A Complete Guide for ML Interviews</a></li><li class="chapter-item expanded "><a href="chapter_004.html"><strong aria-hidden="true">4.</strong> Understanding Mean, Median, and Mode in Skewed Distributions</a></li><li class="chapter-item expanded "><a href="chapter_005.html"><strong aria-hidden="true">5.</strong> Loss Function Robustness: Understanding MAE vs MSE vs RMSE with Outliers</a></li><li class="chapter-item expanded "><a href="chapter_036.html"><strong aria-hidden="true">6.</strong> Understanding Type I and Type II Errors: The Foundation of Statistical Decision Making</a></li><li class="chapter-item expanded "><a href="chapter_063.html"><strong aria-hidden="true">7.</strong> Understanding Dependence vs. Correlation: A Statistical Foundation for Machine Learning</a></li><li class="chapter-item expanded "><a href="chapter_068.html"><strong aria-hidden="true">8.</strong> The Law of Large Numbers: Foundation of Statistical Reliability</a></li><li class="chapter-item expanded "><a href="chapter_069.html"><strong aria-hidden="true">9.</strong> Understanding Selection Bias: The Hidden Threat to Machine Learning Models</a></li><li class="chapter-item expanded affix "><li class="part-title">Data Preprocessing and Feature Engineering</li><li class="chapter-item expanded "><a href="chapter_035.html"><strong aria-hidden="true">10.</strong> Handling Missing Values in High-Missing-Rate Datasets</a></li><li class="chapter-item expanded "><a href="chapter_049.html"><strong aria-hidden="true">11.</strong> Combining Mixed-Dimensional Features for Classification and Regression</a></li><li class="chapter-item expanded "><a href="chapter_057.html"><strong aria-hidden="true">12.</strong> What Happens to Variance When Data is Duplicated?</a></li><li class="chapter-item expanded "><a href="chapter_075.html"><strong aria-hidden="true">13.</strong> Mutual Information Filtering: Understanding Redundant Feature Selection</a></li><li class="chapter-item expanded "><a href="chapter_089.html"><strong aria-hidden="true">14.</strong> Handling Missing Data: A Complete Guide to Imputation Strategies</a></li><li class="chapter-item expanded "><a href="chapter_092.html"><strong aria-hidden="true">15.</strong> Feature Engineering: The Art of Transforming Raw Data into ML Gold</a></li><li class="chapter-item expanded affix "><li class="part-title">Neural Networks and Deep Learning</li><li class="chapter-item expanded "><a href="chapter_013.html"><strong aria-hidden="true">16.</strong> Greedy Layer-wise Pretraining vs Transfer Learning: Understanding Deep Learning&#39;s Evolution</a></li><li class="chapter-item expanded "><a href="chapter_014.html"><strong aria-hidden="true">17.</strong> Freezing Transfer Learning Layers in Transformers</a></li><li class="chapter-item expanded "><a href="chapter_015.html"><strong aria-hidden="true">18.</strong> Dropout During Training vs Inference: The Critical Difference</a></li><li class="chapter-item expanded "><a href="chapter_024.html"><strong aria-hidden="true">19.</strong> The Deep Learning Renaissance: Why Neural Networks Succeeded After Decades</a></li><li class="chapter-item expanded "><a href="chapter_038.html"><strong aria-hidden="true">20.</strong> RNNs vs Transformers: Understanding Sequential Processing Architectures</a></li><li class="chapter-item expanded "><a href="chapter_041.html"><strong aria-hidden="true">21.</strong> The Most Computationally Expensive Operation in Backpropagation</a></li><li class="chapter-item expanded "><a href="chapter_045.html"><strong aria-hidden="true">22.</strong> Understanding the Time Complexity of Self-Attention Layers</a></li><li class="chapter-item expanded "><a href="chapter_055.html"><strong aria-hidden="true">23.</strong> Activation Functions: Understanding Neural Network Decision Making Without Calculations</a></li><li class="chapter-item expanded "><a href="chapter_056.html"><strong aria-hidden="true">24.</strong> Dead ReLU Neurons: Diagnosing and Fixing Inactive Units</a></li><li class="chapter-item expanded "><a href="chapter_064.html"><strong aria-hidden="true">25.</strong> Transformers Beyond Natural Language Processing: Vision Transformers and Computer Vision Applications</a></li><li class="chapter-item expanded "><a href="chapter_065.html"><strong aria-hidden="true">26.</strong> Adapting Pre-trained Neural Networks: From Classification to Regression</a></li><li class="chapter-item expanded "><a href="chapter_066.html"><strong aria-hidden="true">27.</strong> Why Neural Network Training Loss Doesn&#39;t Decrease in Early Epochs</a></li><li class="chapter-item expanded "><a href="chapter_074.html"><strong aria-hidden="true">28.</strong> Weighted Ensemble of Logistic Regression Models as an Artificial Neural Network</a></li><li class="chapter-item expanded "><a href="chapter_081.html"><strong aria-hidden="true">29.</strong> The Hidden Trap: ReLU Before Sigmoid Activation</a></li><li class="chapter-item expanded "><a href="chapter_084.html"><strong aria-hidden="true">30.</strong> Debugging Neural Network Training: When High Loss Meets Small Datasets</a></li><li class="chapter-item expanded "><a href="chapter_085.html"><strong aria-hidden="true">31.</strong> CNNs vs Fully-Connected Networks: Why Spatial Awareness Matters</a></li><li class="chapter-item expanded "><a href="chapter_086.html"><strong aria-hidden="true">32.</strong> Neural Network Weight Initialization: Why Identical Weights Break Everything</a></li><li class="chapter-item expanded affix "><li class="part-title">Optimization and Training</li><li class="chapter-item expanded "><a href="chapter_039.html"><strong aria-hidden="true">33.</strong> Does SGD Always Decrease the Loss Function?</a></li><li class="chapter-item expanded "><a href="chapter_040.html"><strong aria-hidden="true">34.</strong> Why Approximate Solutions in Training Are Perfectly Fine</a></li><li class="chapter-item expanded "><a href="chapter_047.html"><strong aria-hidden="true">35.</strong> Why Gradient Descent Instead of Analytical Solutions?</a></li><li class="chapter-item expanded "><a href="chapter_048.html"><strong aria-hidden="true">36.</strong> The Hessian Matrix in Optimization: Why Deep Learning Avoids Second-Order Methods</a></li><li class="chapter-item expanded "><a href="chapter_061.html"><strong aria-hidden="true">37.</strong> K-means Clustering: Gradient Descent vs Traditional Optimization</a></li><li class="chapter-item expanded "><a href="chapter_062.html"><strong aria-hidden="true">38.</strong> When is Expectation-Maximization Useful? Understanding the EM Algorithm</a></li><li class="chapter-item expanded "><a href="chapter_067.html"><strong aria-hidden="true">39.</strong> The Dangers of Setting Momentum Too High in SGD Optimization</a></li><li class="chapter-item expanded "><a href="chapter_070.html"><strong aria-hidden="true">40.</strong> Weight Decay Scaling Factors: Understanding the Relationship with Batch Size and Learning Rate</a></li><li class="chapter-item expanded "><a href="chapter_079.html"><strong aria-hidden="true">41.</strong> Batch Size Optimization: Understanding the Trade-offs Between Large and Small Batches</a></li><li class="chapter-item expanded "><a href="chapter_093.html"><strong aria-hidden="true">42.</strong> Online Learning vs Batch Learning: When Real-Time Matters</a></li><li class="chapter-item expanded "><a href="chapter_095.html"><strong aria-hidden="true">43.</strong> Hyperparameter Tuning: The Art and Science of Model Optimization</a></li><li class="chapter-item expanded affix "><li class="part-title">Model Evaluation and Validation</li><li class="chapter-item expanded "><a href="chapter_025.html"><strong aria-hidden="true">44.</strong> When Training and Testing Accuracy Converge: Understanding Model Performance</a></li><li class="chapter-item expanded "><a href="chapter_042.html"><strong aria-hidden="true">45.</strong> Classification with Noisy Labels: Handling Incorrect Training Data</a></li><li class="chapter-item expanded "><a href="chapter_043.html"><strong aria-hidden="true">46.</strong> When Perfection Becomes a Problem: Logistic Regression and Perfectly Separable Data</a></li><li class="chapter-item expanded "><a href="chapter_044.html"><strong aria-hidden="true">47.</strong> Debugging Production ML Models: When Great Training Performance Meets Production Reality</a></li><li class="chapter-item expanded "><a href="chapter_050.html"><strong aria-hidden="true">48.</strong> When A/B Tests Show No Significant Results: A Complete Guide to Next Steps</a></li><li class="chapter-item expanded "><a href="chapter_060.html"><strong aria-hidden="true">49.</strong> Linear Regression with Noisy Inputs: Objective Functions and Their Effects</a></li><li class="chapter-item expanded "><a href="chapter_076.html"><strong aria-hidden="true">50.</strong> The Bias-Variance Tradeoff: Understanding Model Complexity Through Polynomial Regression</a></li><li class="chapter-item expanded "><a href="chapter_078.html"><strong aria-hidden="true">51.</strong> Choosing Evaluation Metrics for Criminal Identification Systems</a></li><li class="chapter-item expanded "><a href="chapter_080.html"><strong aria-hidden="true">52.</strong> Theoretical Limits of Classification: When Perfect Accuracy is Impossible</a></li><li class="chapter-item expanded "><a href="chapter_082.html"><strong aria-hidden="true">53.</strong> Data Leakage in Class Imbalance: The Hidden Trap of Premature Duplication</a></li><li class="chapter-item expanded "><a href="chapter_090.html"><strong aria-hidden="true">54.</strong> Cross-Validation: The Gold Standard for Model Evaluation</a></li><li class="chapter-item expanded "><a href="chapter_094.html"><strong aria-hidden="true">55.</strong> Handling Class Imbalance in Classification: A Complete Guide to Balanced Machine Learning</a></li><li class="chapter-item expanded affix "><li class="part-title">Mathematical Foundations</li><li class="chapter-item expanded "><a href="chapter_019.html"><strong aria-hidden="true">56.</strong> Why Use Sigmoid for Numerical Prediction: Understanding Bounded Outputs</a></li><li class="chapter-item expanded "><a href="chapter_020.html"><strong aria-hidden="true">57.</strong> The Exponential Decay Function: A Mathematical Foundation for Machine Learning</a></li><li class="chapter-item expanded "><a href="chapter_021.html"><strong aria-hidden="true">58.</strong> From Binary Bits to Continuous Probabilities: Understanding the Sigmoid Function</a></li><li class="chapter-item expanded "><a href="chapter_022.html"><strong aria-hidden="true">59.</strong> PCA and Correlated Variables: To Remove or Not to Remove?</a></li><li class="chapter-item expanded "><a href="chapter_023.html"><strong aria-hidden="true">60.</strong> Understanding Dot Product Computational Complexity: How It Scales with N</a></li><li class="chapter-item expanded "><a href="chapter_010.html"><strong aria-hidden="true">61.</strong> Clock Angle Problems: Mathematical Reasoning in Technical Interviews</a></li><li class="chapter-item expanded "><a href="chapter_077.html"><strong aria-hidden="true">62.</strong> The Softmax Function and Scalar Multiplication: A Common ML Interview Misconception</a></li><li class="chapter-item expanded affix "><li class="part-title">Probability and Statistics</li><li class="chapter-item expanded "><a href="chapter_026.html"><strong aria-hidden="true">63.</strong> The Fair and Unfair Coin Problem: Mastering Bayesian Probability for Interviews</a></li><li class="chapter-item expanded "><a href="chapter_027.html"><strong aria-hidden="true">64.</strong> Expected Waiting Time for Extreme Values in Normal Distributions</a></li><li class="chapter-item expanded "><a href="chapter_028.html"><strong aria-hidden="true">65.</strong> Generating Fair Odds from an Unfair Coin: Von Neumann&#39;s Elegant Solution</a></li><li class="chapter-item expanded "><a href="chapter_029.html"><strong aria-hidden="true">66.</strong> Maximum Likelihood Estimation for Exponential Distribution: Customer Lifetime Modeling</a></li><li class="chapter-item expanded "><a href="chapter_030.html"><strong aria-hidden="true">67.</strong> Probability Sampling for Feature Release Decisions</a></li><li class="chapter-item expanded "><a href="chapter_031.html"><strong aria-hidden="true">68.</strong> The Gambler&#39;s Ruin Problem: Asymmetric Coin Flip Probability</a></li><li class="chapter-item expanded "><a href="chapter_032.html"><strong aria-hidden="true">69.</strong> Regression Slope Symmetry: The Hidden Mathematical Relationship</a></li><li class="chapter-item expanded affix "><li class="part-title">Machine Learning Algorithms</li><li class="chapter-item expanded "><a href="chapter_046.html"><strong aria-hidden="true">70.</strong> Random Forest: Understanding the Power of Randomness in Ensemble Learning</a></li><li class="chapter-item expanded "><a href="chapter_051.html"><strong aria-hidden="true">71.</strong> Analyzing Network Effects: When Family Members Join Social Media Platforms</a></li><li class="chapter-item expanded "><a href="chapter_052.html"><strong aria-hidden="true">72.</strong> Logistic Regression vs Decision Trees: When to Choose Which Algorithm</a></li><li class="chapter-item expanded "><a href="chapter_053.html"><strong aria-hidden="true">73.</strong> High-Dimensional Models with Poor Performance: The Curse of Dimensionality</a></li><li class="chapter-item expanded "><a href="chapter_054.html"><strong aria-hidden="true">74.</strong> When Should We Use Naive Bayes with Laplace Smoothing? A Complete Guide with Practical Examples</a></li><li class="chapter-item expanded "><a href="chapter_087.html"><strong aria-hidden="true">75.</strong> High-Dimensional Data Challenges: Navigating the Curse of Dimensionality</a></li><li class="chapter-item expanded "><a href="chapter_088.html"><strong aria-hidden="true">76.</strong> L1 vs L2 Regularization: Understanding Ridge, Lasso, and the Art of Model Generalization</a></li><li class="chapter-item expanded "><a href="chapter_091.html"><strong aria-hidden="true">77.</strong> Bagging vs Boosting: Understanding Ensemble Learning Strategies</a></li><li class="chapter-item expanded affix "><li class="part-title">Ensemble Methods</li><li class="chapter-item expanded "><a href="chapter_008.html"><strong aria-hidden="true">78.</strong> Why Ensembles Typically Outperform Individual Models (And When They Don&#39;t)</a></li><li class="chapter-item expanded "><a href="chapter_011.html"><strong aria-hidden="true">79.</strong> Optimizing Labeled Data: Three Industry-Proven Strategies</a></li><li class="chapter-item expanded "><a href="chapter_012.html"><strong aria-hidden="true">80.</strong> Few-Shot Learning and Meta-Learning: Learning to Learn with Limited Data</a></li><li class="chapter-item expanded affix "><li class="part-title">Generative Models and Advanced AI</li><li class="chapter-item expanded "><a href="chapter_016.html"><strong aria-hidden="true">81.</strong> Variational Autoencoders: Understanding the Need for Variation and Its Connection to NLU vs NLG</a></li><li class="chapter-item expanded "><a href="chapter_017.html"><strong aria-hidden="true">82.</strong> Generative Models: Training vs Inference in Text Generation</a></li><li class="chapter-item expanded "><a href="chapter_018.html"><strong aria-hidden="true">83.</strong> Subword Tokenization: Breaking Down the Building Blocks of Language</a></li><li class="chapter-item expanded "><a href="chapter_037.html"><strong aria-hidden="true">84.</strong> Multimodal Alignment and Cross-Modal Attention Mechanisms</a></li><li class="chapter-item expanded "><a href="chapter_058.html"><strong aria-hidden="true">85.</strong> Identifying Synonyms from Large Text Corpora</a></li><li class="chapter-item expanded "><a href="chapter_071.html"><strong aria-hidden="true">86.</strong> Fuzzy Logic: Handling Uncertainty in Intelligent Systems</a></li><li class="chapter-item expanded "><a href="chapter_072.html"><strong aria-hidden="true">87.</strong> Understanding Latent Variables vs Embeddings in Stable Diffusion</a></li><li class="chapter-item expanded affix "><li class="part-title">Recommendation Systems</li><li class="chapter-item expanded "><a href="chapter_006.html"><strong aria-hidden="true">88.</strong> Content-Based vs. Collaborative Filtering in Recommendation Systems</a></li><li class="chapter-item expanded "><a href="chapter_007.html"><strong aria-hidden="true">89.</strong> Building a Restaurant Recommendation System for TripAdvisor</a></li><li class="chapter-item expanded affix "><li class="part-title">Computer Vision and Object Detection</li><li class="chapter-item expanded "><a href="chapter_009.html"><strong aria-hidden="true">90.</strong> Focal Loss: Solving Class Imbalance in Object Detection</a></li><li class="chapter-item expanded "><a href="chapter_033.html"><strong aria-hidden="true">91.</strong> Face Verification Systems: Building ML-Powered Identity Solutions</a></li><li class="chapter-item expanded affix "><li class="part-title">System Design and Applications</li><li class="chapter-item expanded "><a href="chapter_034.html"><strong aria-hidden="true">92.</strong> Alpha-Beta Pruning: The Key Optimization for Minimax Algorithms</a></li><li class="chapter-item expanded "><a href="chapter_059.html"><strong aria-hidden="true">93.</strong> Modeling Airbnb New Listing Revenue: A Complete ML System Design</a></li><li class="chapter-item expanded "><a href="chapter_073.html"><strong aria-hidden="true">94.</strong> Building a Churn Prediction Model for Robinhood Users</a></li><li class="chapter-item expanded "><a href="chapter_083.html"><strong aria-hidden="true">95.</strong> Model Extrapolation and Reverse Optimization: The Car Fuel Efficiency Problem</a></li></ol>';
        // Set the current, active page, and reveal it if it's hidden
        let current_page = document.location.href.toString().split("#")[0].split("?")[0];
        if (current_page.endsWith("/")) {
            current_page += "index.html";
        }
        var links = Array.prototype.slice.call(this.querySelectorAll("a"));
        var l = links.length;
        for (var i = 0; i < l; ++i) {
            var link = links[i];
            var href = link.getAttribute("href");
            if (href && !href.startsWith("#") && !/^(?:[a-z+]+:)?\/\//.test(href)) {
                link.href = path_to_root + href;
            }
            // The "index" page is supposed to alias the first chapter in the book.
            if (link.href === current_page || (i === 0 && path_to_root === "" && current_page.endsWith("/index.html"))) {
                link.classList.add("active");
                var parent = link.parentElement;
                if (parent && parent.classList.contains("chapter-item")) {
                    parent.classList.add("expanded");
                }
                while (parent) {
                    if (parent.tagName === "LI" && parent.previousElementSibling) {
                        if (parent.previousElementSibling.classList.contains("chapter-item")) {
                            parent.previousElementSibling.classList.add("expanded");
                        }
                    }
                    parent = parent.parentElement;
                }
            }
        }
        // Track and set sidebar scroll position
        this.addEventListener('click', function(e) {
            if (e.target.tagName === 'A') {
                sessionStorage.setItem('sidebar-scroll', this.scrollTop);
            }
        }, { passive: true });
        var sidebarScrollTop = sessionStorage.getItem('sidebar-scroll');
        sessionStorage.removeItem('sidebar-scroll');
        if (sidebarScrollTop) {
            // preserve sidebar scroll position when navigating via links within sidebar
            this.scrollTop = sidebarScrollTop;
        } else {
            // scroll sidebar to current active section when navigating via "next/previous chapter" buttons
            var activeSection = document.querySelector('#sidebar .active');
            if (activeSection) {
                activeSection.scrollIntoView({ block: 'center' });
            }
        }
        // Toggle buttons
        var sidebarAnchorToggles = document.querySelectorAll('#sidebar a.toggle');
        function toggleSection(ev) {
            ev.currentTarget.parentElement.classList.toggle('expanded');
        }
        Array.from(sidebarAnchorToggles).forEach(function (el) {
            el.addEventListener('click', toggleSection);
        });
    }
}
window.customElements.define("mdbook-sidebar-scrollbox", MDBookSidebarScrollbox);
