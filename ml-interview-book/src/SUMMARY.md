# Summary

[Introduction](./introduction.md)

# Fundamentals

- [Why We Use Smaller Learning Rates: The Key to Stable ML Training](./chapter_001.md)
- [Train-Test Split Ratios: Beyond the 80:20 Rule](./chapter_002.md)
- [Understanding Covariance vs Correlation: A Complete Guide for ML Interviews](./chapter_003.md)
- [Understanding Mean, Median, and Mode in Skewed Distributions](./chapter_004.md)
- [Loss Function Robustness: Understanding MAE vs MSE vs RMSE with Outliers](./chapter_005.md)
- [Understanding Type I and Type II Errors: The Foundation of Statistical Decision Making](./chapter_036.md)
- [Understanding Dependence vs. Correlation: A Statistical Foundation for Machine Learning](./chapter_063.md)
- [The Law of Large Numbers: Foundation of Statistical Reliability](./chapter_068.md)
- [Understanding Selection Bias: The Hidden Threat to Machine Learning Models](./chapter_069.md)

# Data Preprocessing and Feature Engineering

- [Handling Missing Values in High-Missing-Rate Datasets](./chapter_035.md)
- [Combining Mixed-Dimensional Features for Classification and Regression](./chapter_049.md)
- [What Happens to Variance When Data is Duplicated?](./chapter_057.md)
- [Mutual Information Filtering: Understanding Redundant Feature Selection](./chapter_075.md)
- [Handling Missing Data: A Complete Guide to Imputation Strategies](./chapter_089.md)
- [Feature Engineering: The Art of Transforming Raw Data into ML Gold](./chapter_092.md)

# Neural Networks and Deep Learning

- [Greedy Layer-wise Pretraining vs Transfer Learning: Understanding Deep Learning's Evolution](./chapter_013.md)
- [Freezing Transfer Learning Layers in Transformers](./chapter_014.md)
- [Dropout During Training vs Inference: The Critical Difference](./chapter_015.md)
- [The Deep Learning Renaissance: Why Neural Networks Succeeded After Decades](./chapter_024.md)
- [RNNs vs Transformers: Understanding Sequential Processing Architectures](./chapter_038.md)
- [The Most Computationally Expensive Operation in Backpropagation](./chapter_041.md)
- [Understanding the Time Complexity of Self-Attention Layers](./chapter_045.md)
- [Activation Functions: Understanding Neural Network Decision Making Without Calculations](./chapter_055.md)
- [Dead ReLU Neurons: Diagnosing and Fixing Inactive Units](./chapter_056.md)
- [Transformers Beyond Natural Language Processing: Vision Transformers and Computer Vision Applications](./chapter_064.md)
- [Adapting Pre-trained Neural Networks: From Classification to Regression](./chapter_065.md)
- [Why Neural Network Training Loss Doesn't Decrease in Early Epochs](./chapter_066.md)
- [Weighted Ensemble of Logistic Regression Models as an Artificial Neural Network](./chapter_074.md)
- [The Hidden Trap: ReLU Before Sigmoid Activation](./chapter_081.md)
- [Debugging Neural Network Training: When High Loss Meets Small Datasets](./chapter_084.md)
- [CNNs vs Fully-Connected Networks: Why Spatial Awareness Matters](./chapter_085.md)
- [Neural Network Weight Initialization: Why Identical Weights Break Everything](./chapter_086.md)

# Optimization and Training

- [Does SGD Always Decrease the Loss Function?](./chapter_039.md)
- [Why Approximate Solutions in Training Are Perfectly Fine](./chapter_040.md)
- [Why Gradient Descent Instead of Analytical Solutions?](./chapter_047.md)
- [The Hessian Matrix in Optimization: Why Deep Learning Avoids Second-Order Methods](./chapter_048.md)
- [K-means Clustering: Gradient Descent vs Traditional Optimization](./chapter_061.md)
- [When is Expectation-Maximization Useful? Understanding the EM Algorithm](./chapter_062.md)
- [The Dangers of Setting Momentum Too High in SGD Optimization](./chapter_067.md)
- [Weight Decay Scaling Factors: Understanding the Relationship with Batch Size and Learning Rate](./chapter_070.md)
- [Batch Size Optimization: Understanding the Trade-offs Between Large and Small Batches](./chapter_079.md)
- [Online Learning vs Batch Learning: When Real-Time Matters](./chapter_093.md)
- [Hyperparameter Tuning: The Art and Science of Model Optimization](./chapter_095.md)

# Model Evaluation and Validation

- [When Training and Testing Accuracy Converge: Understanding Model Performance](./chapter_025.md)
- [Classification with Noisy Labels: Handling Incorrect Training Data](./chapter_042.md)
- [When Perfection Becomes a Problem: Logistic Regression and Perfectly Separable Data](./chapter_043.md)
- [Debugging Production ML Models: When Great Training Performance Meets Production Reality](./chapter_044.md)
- [When A/B Tests Show No Significant Results: A Complete Guide to Next Steps](./chapter_050.md)
- [Linear Regression with Noisy Inputs: Objective Functions and Their Effects](./chapter_060.md)
- [The Bias-Variance Tradeoff: Understanding Model Complexity Through Polynomial Regression](./chapter_076.md)
- [Choosing Evaluation Metrics for Criminal Identification Systems](./chapter_078.md)
- [Theoretical Limits of Classification: When Perfect Accuracy is Impossible](./chapter_080.md)
- [Data Leakage in Class Imbalance: The Hidden Trap of Premature Duplication](./chapter_082.md)
- [Cross-Validation: The Gold Standard for Model Evaluation](./chapter_090.md)
- [Handling Class Imbalance in Classification: A Complete Guide to Balanced Machine Learning](./chapter_094.md)

# Mathematical Foundations

- [Why Use Sigmoid for Numerical Prediction: Understanding Bounded Outputs](./chapter_019.md)
- [The Exponential Decay Function: A Mathematical Foundation for Machine Learning](./chapter_020.md)
- [From Binary Bits to Continuous Probabilities: Understanding the Sigmoid Function](./chapter_021.md)
- [PCA and Correlated Variables: To Remove or Not to Remove?](./chapter_022.md)
- [Understanding Dot Product Computational Complexity: How It Scales with N](./chapter_023.md)
- [Clock Angle Problems: Mathematical Reasoning in Technical Interviews](./chapter_010.md)
- [The Softmax Function and Scalar Multiplication: A Common ML Interview Misconception](./chapter_077.md)

# Probability and Statistics

- [The Fair and Unfair Coin Problem: Mastering Bayesian Probability for Interviews](./chapter_026.md)
- [Expected Waiting Time for Extreme Values in Normal Distributions](./chapter_027.md)
- [Generating Fair Odds from an Unfair Coin: Von Neumann's Elegant Solution](./chapter_028.md)
- [Maximum Likelihood Estimation for Exponential Distribution: Customer Lifetime Modeling](./chapter_029.md)
- [Probability Sampling for Feature Release Decisions](./chapter_030.md)
- [The Gambler's Ruin Problem: Asymmetric Coin Flip Probability](./chapter_031.md)
- [Regression Slope Symmetry: The Hidden Mathematical Relationship](./chapter_032.md)

# Machine Learning Algorithms

- [Random Forest: Understanding the Power of Randomness in Ensemble Learning](./chapter_046.md)
- [Analyzing Network Effects: When Family Members Join Social Media Platforms](./chapter_051.md)
- [Logistic Regression vs Decision Trees: When to Choose Which Algorithm](./chapter_052.md)
- [High-Dimensional Models with Poor Performance: The Curse of Dimensionality](./chapter_053.md)
- [When Should We Use Naive Bayes with Laplace Smoothing? A Complete Guide with Practical Examples](./chapter_054.md)
- [High-Dimensional Data Challenges: Navigating the Curse of Dimensionality](./chapter_087.md)
- [L1 vs L2 Regularization: Understanding Ridge, Lasso, and the Art of Model Generalization](./chapter_088.md)
- [Bagging vs Boosting: Understanding Ensemble Learning Strategies](./chapter_091.md)

# Ensemble Methods

- [Why Ensembles Typically Outperform Individual Models (And When They Don't)](./chapter_008.md)
- [Optimizing Labeled Data: Three Industry-Proven Strategies](./chapter_011.md)
- [Few-Shot Learning and Meta-Learning: Learning to Learn with Limited Data](./chapter_012.md)

# Generative Models and Advanced AI

- [Variational Autoencoders: Understanding the Need for Variation and Its Connection to NLU vs NLG](./chapter_016.md)
- [Generative Models: Training vs Inference in Text Generation](./chapter_017.md)
- [Subword Tokenization: Breaking Down the Building Blocks of Language](./chapter_018.md)
- [Multimodal Alignment and Cross-Modal Attention Mechanisms](./chapter_037.md)
- [Identifying Synonyms from Large Text Corpora](./chapter_058.md)
- [Fuzzy Logic: Handling Uncertainty in Intelligent Systems](./chapter_071.md)
- [Understanding Latent Variables vs Embeddings in Stable Diffusion](./chapter_072.md)

# Recommendation Systems

- [Content-Based vs. Collaborative Filtering in Recommendation Systems](./chapter_006.md)
- [Building a Restaurant Recommendation System for TripAdvisor](./chapter_007.md)

# Computer Vision and Object Detection

- [Focal Loss: Solving Class Imbalance in Object Detection](./chapter_009.md)
- [Face Verification Systems: Building ML-Powered Identity Solutions](./chapter_033.md)

# System Design and Applications

- [Alpha-Beta Pruning: The Key Optimization for Minimax Algorithms](./chapter_034.md)
- [Modeling Airbnb New Listing Revenue: A Complete ML System Design](./chapter_059.md)
- [Building a Churn Prediction Model for Robinhood Users](./chapter_073.md)
- [Model Extrapolation and Reverse Optimization: The Car Fuel Efficiency Problem](./chapter_083.md)

*This comprehensive guide covers 95 essential machine learning interview questions from top tech companies, providing detailed explanations and practical insights for each topic.*